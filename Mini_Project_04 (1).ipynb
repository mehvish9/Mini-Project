{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0rAUezF2ZoH"
      },
      "outputs": [],
      "source": [
        "# Note- After running this cell, restart session and DONT run this again\n",
        "!pip install --upgrade --force-reinstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2Qduj9N2bIT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbEZFzPl2fER"
      },
      "outputs": [],
      "source": [
        "# Installation for GPU llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.28  --force-reinstall --upgrade --no-cache-dir -q 2>/dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri8YZmRw2wp8"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken pypdf langchain langchain-community chromadb sentence-transformers huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvq7-a7E23db"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader, PyPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from google.colab import userdata, drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnbFEHSI29L5"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aob2PmPd4J3i"
      },
      "outputs": [],
      "source": [
        "apple_pdf_path = \"/content/HBR_How_Apple_Is_Organized_For_Innovation-4.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-uqrUi-3cb8"
      },
      "outputs": [],
      "source": [
        "pdf_loader = PyPDFLoader(apple_pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hspW4crU4QWm"
      },
      "outputs": [],
      "source": [
        "apple = pdf_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCdwsFBX4UgO"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    print(f\"Page Number : {i+1}\",end=\"\\n\")\n",
        "    print(apple[i].page_content,end=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx1tTStK4bxT"
      },
      "outputs": [],
      "source": [
        "apple[5].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69vQYSX74i13"
      },
      "outputs": [],
      "source": [
        "len(apple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAuOkSxz4ndJ"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name='cl100k_base',\n",
        "    chunk_size=512,\n",
        "    chunk_overlap= 20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1VG5xZq4rpI"
      },
      "outputs": [],
      "source": [
        "document_chunks = pdf_loader.load_and_split(text_splitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj4769UR4v2E"
      },
      "outputs": [],
      "source": [
        "document_chunks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIX2kggJ47_Z"
      },
      "outputs": [],
      "source": [
        "len(document_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge9JchNW4_z7"
      },
      "outputs": [],
      "source": [
        "document_chunks[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJNgMwp65DU3"
      },
      "outputs": [],
      "source": [
        "document_chunks[-2].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwQq2sGz5G3d"
      },
      "outputs": [],
      "source": [
        "document_chunks[-1].page_content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformerEmbeddings(model_name='thenlper/gte-large')"
      ],
      "metadata": {
        "id": "zE6v7ALBvyFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_1 = embedding_model.embed_query(document_chunks[0].page_content)\n",
        "embedding_2 = embedding_model.embed_query(document_chunks[1].page_content)"
      ],
      "metadata": {
        "id": "tuXwjMgnv2pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimension of the embedding vector \",len(embedding_1))\n",
        "len(embedding_1)==len(embedding_2)"
      ],
      "metadata": {
        "id": "nZmV6rokv6sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "out_dir = 'apple_db'\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "  os.makedirs(out_dir)"
      ],
      "metadata": {
        "id": "9KqpMI_1v-CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    document_chunks,\n",
        "    embedding_model,\n",
        "    persist_directory=out_dir\n",
        ")"
      ],
      "metadata": {
        "id": "BAEofCQ7wAcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma(persist_directory=out_dir,embedding_function=embedding_model)"
      ],
      "metadata": {
        "id": "9jg7T_CQwDa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.embeddings"
      ],
      "metadata": {
        "id": "bK-i3-4kwGdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"Apple Steve Jobs iPhone \",k=3)"
      ],
      "metadata": {
        "id": "ySJ8B6pwwIwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type='similarity',\n",
        "    search_kwargs={'k': 2}\n",
        ")"
      ],
      "metadata": {
        "id": "5vl-BYE7wL7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel_docs = retriever.get_relevant_documents(\"How does does Apple develop and ship products that requires good coordination between the teams?\")\n",
        "rel_docs"
      ],
      "metadata": {
        "id": "25ps4hXWwQA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtDATReA1ptY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "SoP5XuZmwSzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using mistral\n",
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\"\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename\n",
        ")"
      ],
      "metadata": {
        "id": "8YdXZUGDwWxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=2300,\n",
        "    n_gpu_layers=38,\n",
        "    n_batch=512\n",
        ")"
      ],
      "metadata": {
        "id": "P5k6VQuBwZlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"How does does Apple develop and ship products that requires good coordination between the teams?\")['choices'][0]['text']"
      ],
      "metadata": {
        "id": "Zm23J2Y5wceR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qna_system_message = \"\"\"\n",
        "You are an assistant whose work is to review the report and provide the appropriate answers from the context.\n",
        "User input will have the context required by you to answer user questions.\n",
        "This context will begin with the token: ###Context.\n",
        "The context contains references to specific portions of a document relevant to the user query.\n",
        "\n",
        "User questions will begin with the token: ###Question.\n",
        "\n",
        "Please answer only using the context provided in the input. Do not mention anything about the context in your final answer.\n",
        "\n",
        "If the answer is not found in the context, respond \"I don't know\".\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ry2IDNZswg_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qna_user_message_template = \"\"\"\n",
        "###Context\n",
        "Here are some documents that are relevant to the question mentioned below.\n",
        "{context}\n",
        "\n",
        "###Question\n",
        "{question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "e3dPpQOGwu-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rag_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=k)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "\n",
        "    # Combine document chunks into a single context\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    user_message = qna_user_message_template.replace('{context}', context_for_query)\n",
        "    user_message = user_message.replace('{question}', user_input)\n",
        "\n",
        "    prompt = qna_system_message + '\\n' + user_message\n",
        "\n",
        "    # Generate the response\n",
        "    try:\n",
        "        response = llm(\n",
        "                  prompt=prompt,\n",
        "                  max_tokens=max_tokens,\n",
        "                  temperature=temperature,\n",
        "                  top_p=top_p,\n",
        "                  top_k=top_k\n",
        "                  )\n",
        "\n",
        "        # Extract and print the model's response\n",
        "        response = response['choices'][0]['text'].strip()\n",
        "    except Exception as e:\n",
        "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "ZTarFKZ5wxtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using only LLM\n",
        "llm(\"Who are the authors of this article and who published this article ?\")['choices'][0]['text']"
      ],
      "metadata": {
        "id": "lxsHKJffw0sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using RAG\n",
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "print(generate_rag_response(user_input))"
      ],
      "metadata": {
        "id": "GzwRu2oDw3kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using only LLM\n",
        "llm(\"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\")['choices'][0]['text']"
      ],
      "metadata": {
        "id": "eN03yrp8w54v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using RAG\n",
        "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
        "generate_rag_response(user_input_2)"
      ],
      "metadata": {
        "id": "r4T2bqTMw8lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
        "generate_rag_response(user_input_3)"
      ],
      "metadata": {
        "id": "vhYP0RP-w-5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "generate_rag_response(user_input, max_tokens=100)"
      ],
      "metadata": {
        "id": "i2ylu5zHxBtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
        "generate_rag_response(user_input_2, temperature=0.1, max_tokens=350)"
      ],
      "metadata": {
        "id": "kOGKIC1RxGAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
        "generate_rag_response(user_input_3, top_p=0.98, top_k=20, max_tokens=256)"
      ],
      "metadata": {
        "id": "YYOI6CSixJO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groundedness_rater_system_message = \"\"\"\n",
        "You are tasked with rating AI generated answers to questions posed by users.\n",
        "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
        "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
        "\n",
        "Evaluation criteria:\n",
        "The task is to judge the extent to which the metric is followed by the answer.\n",
        "1 - The metric is not followed at all\n",
        "2 - The metric is followed only to a limited extent\n",
        "3 - The metric is followed to a good extent\n",
        "4 - The metric is followed mostly\n",
        "5 - The metric is followed completely\n",
        "\n",
        "Metric:\n",
        "The answer should be derived only from the information presented in the context\n",
        "\n",
        "Instructions:\n",
        "1. First write down the steps that are needed to evaluate the answer as per the metric.\n",
        "2. Give a step-by-step explanation if the answer adheres to the metric considering the question and context as the input.\n",
        "3. Next, evaluate the extent to which the metric is followed.\n",
        "4. Use the previous information to rate the answer using the evaluaton criteria and assign a score.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rsumn9TvxL-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevance_rater_system_message = \"\"\"\n",
        "You are tasked with rating AI generated answers to questions posed by users.\n",
        "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
        "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
        "\n",
        "Evaluation criteria:\n",
        "The task is to judge the extent to which the metric is followed by the answer.\n",
        "1 - The metric is not followed at all\n",
        "2 - The metric is followed only to a limited extent\n",
        "3 - The metric is followed to a good extent\n",
        "4 - The metric is followed mostly\n",
        "5 - The metric is followed completely\n",
        "\n",
        "Metric:\n",
        "Relevance measures how well the answer addresses the main aspects of the question, based on the context.\n",
        "Consider whether all and only the important aspects are contained in the answer when evaluating relevance.\n",
        "\n",
        "Instructions:\n",
        "1. First write down the steps that are needed to evaluate the context as per the metric.\n",
        "2. Give a step-by-step explanation if the context adheres to the metric considering the question as the input.\n",
        "3. Next, evaluate the extent to which the metric is followed.\n",
        "4. Use the previous information to rate the context using the evaluaton criteria and assign a score.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wBwaK_9kxUjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message_template = \"\"\"\n",
        "###Question\n",
        "{question}\n",
        "\n",
        "###Context\n",
        "{context}\n",
        "\n",
        "###Answer\n",
        "{answer}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TFz_A7p5xbsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ground_relevance_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=3)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    prompt = f\"\"\"[INST]{qna_system_message}\\n\n",
        "                {'user'}: {qna_user_message_template.format(context=context_for_query, question=user_input)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response = llm(\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    answer =  response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    groundedness_prompt = f\"\"\"[INST]{groundedness_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    relevance_prompt = f\"\"\"[INST]{relevance_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response_1 = llm(\n",
        "            prompt=groundedness_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    response_2 = llm(\n",
        "            prompt=relevance_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    return response_1['choices'][0]['text'],response_2['choices'][0]['text']"
      ],
      "metadata": {
        "id": "IQtjA4moxcqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Who are the authors of this article and who published this article ?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input,max_tokens=350)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ],
      "metadata": {
        "id": "gPzY7S_zxfcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
        "ground,rel = generate_ground_relevance_response(user_input_2,max_tokens=500)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ],
      "metadata": {
        "id": "rA5aVyWoxiJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
        "ground,rel = generate_ground_relevance_response(user_input_3,max_tokens=500)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ],
      "metadata": {
        "id": "HTRl_y2Qxk7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuzwjVztxntE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}